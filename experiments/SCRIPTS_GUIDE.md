### Project Scripts Guide

Этот документ описывает ключевые скрипты проекта: назначение, входы/выходы, важные параметры и примеры запуска.

### 1) `experiments/fetch_arxiv_20_each.py`
- **Назначение**: выгрузка по 20 документов для тем `text_mining` и `information_retrieval` через arXiv API в CSV.
- **Вход**: интернет, arXiv API.
- **Выход**: CSV файлы, например `data/arxiv_docs/text_mining.csv`, `data/arxiv_docs/information_retrieval.csv`.
- **Ключевые параметры**: внутри скрипта скорректированы запросы (`cat:cs.CL OR cat:cs.IR ...`).
- **Пример**:
```bash
python experiments/fetch_arxiv_20_each.py \
  --out_dir data/arxiv_docs
```

- **Параметры и обоснование**:
  - `--out_dir` (обяз.) — директория для сохранения CSV; явный контроль места вывода.
  - Внутренние параметры запроса к arXiv: ограничение по категориям (`cs.CL`, `cs.IR`) и ключевым словам, чтобы уменьшить шум и пустые ответы.

- **Основные функции/логика**:
  - Формирование запросов к arXiv API с пагинацией и лимитом.
  - Нормализация полей (`title`, `abstract`, `categories`, `published`).
  - Защита от пустых результатов: повторные попытки с более широким запросом.

- **Краевые случаи**:
  - Пустая выдача → расширение запроса OR-комбинациями.
  - Дубликаты → фильтрация по идентификатору/названию.

### 2) `experiments/prepare_corpus_from_csv.py`
- **Назначение**: конвертация CSV в корпус `.txt` файлов (по строке → один файл).
- **Вход**: CSV из предыдущего шага.
- **Выход**: папки с `.txt` файлами (для human корпуса).
- **Основные флаги**:
  - `--csv`: путь к CSV
  - `--out_dir`: папка для `.txt`
- **Пример**:
```bash
python experiments/prepare_corpus_from_csv.py \
  --csv data/arxiv_docs/text_mining.csv \
  --out_dir data/human/text_mining
```

- **Параметры и обоснование**:
  - `--csv` (обяз.) — явное указание источника данных для воспроизводимости.
  - `--out_dir` (обяз.) — раздельные папки по темам для удобства экспериментов.

- **Основные функции/логика**:
  - Чтение CSV, безопасное извлечение `title`/`abstract`.
  - Нумерация файлов и формат заголовка: `Title:\n...\n\nAbstract:\n...` для единообразия с синтетикой.
  - Пропуск пустых записей.

- **Краевые случаи**:
  - Пустой CSV → информативная ошибка.
  - Некорректная кодировка → чтение в `utf-8` и оповещение.

### 3) `experiments/generate_synthetic_hf_api.py`
- **Назначение**: генерация синтетических аннотаций через Hugging Face Inference API (без локальных весов).
- **Вход**: CSV с человеческими аннотациями (для подсказки/контекста), HF_TOKEN.
- **Выход**: `synthetic_XXX.txt` и `metadata.json` в указанной папке.
- **Основные флаги**:
  - `--human_csv` (required): CSV с человеческими аннотациями
  - `--output_dir` (required): папка для синтетики
  - `--count` (default=20): целевое число файлов (дозаполнение поддерживается)
  - `--model` (required): id модели на HF (например, `meta-llama/Meta-Llama-3.1-70B-Instruct`)
  - `--hf_token`: токен (или берётся из `HF_TOKEN`)
  - `--topic_hint`: тема, если из имени CSV не извлекается автоматически
  - `--sleep_s`: пауза между запросами
  - `--mode`: `auto | chat | text`, с фолбэками при неподдерживаемом режиме
  - `--stop`: стоп-сиквенсы для text режима
- **Внутренние параметры генерации**: `max_new_tokens=500`, `temperature=0.7`, `top_p=0.95`, `repetition_penalty=1.05` (для text), очистка chain-of-thought.
- **Пример**:
```bash
export HF_TOKEN=hf_xxx
python experiments/generate_synthetic_hf_api.py \
  --human_csv data/arxiv_docs/information_retrieval.csv \
  --output_dir data/ai/llama/information_retrieval \
  --count 20 \
  --model meta-llama/Meta-Llama-3.1-70B-Instruct \
  --mode auto
```

- **Параметры и обоснование (детально)**:
  - `--human_csv` (обяз.) — даёт реальный контекст домена; повышает релевантность синтетики.
  - `--output_dir` (обяз.) — чёткая сегрегация по модели/теме.
  - `--count`=20 — целевой объём; дозаполнение защищает от перезаписи.
  - `--model` (обяз.) — выбор Instruct‑моделей улучшает соответствие требованиям промпта.
  - `--mode`=`auto` — авто‑фолбэк между `chat` и `text` снижает вероятность сбоев у разных провайдеров.
  - `--sleep_s`=0.7 — щадит rate‑limit API.
  - `--stop` — мягкая остановка в `text_generation` для аккуратного завершения.
  - Внутренние: `max_new_tokens`=500 (целевые 300–500 слов), `temperature`=0.7 (баланс креативности/строгости), `top_p`=0.95 (контроль хвоста), `repetition_penalty`=1.05 (умеренное наказание повторов в text‑режиме).

- **Функции**:
  - `build_client(...)` — создаёт клиент HF, валидирует токен.
  - `sanitize_output(...)` — вырезает chain‑of‑thought/префиксы.
  - `generate_one(...)` — инкапсулирует `chat_completion`/`text_generation` + фолбэки и stop‑seq.
  - `main()` — чтение CSV, авто‑определение темы, дозаполнение, сохранение txt и `metadata.json`.

- **Краевые случаи**:
  - Provider без `text-generation` → авто‑фолбэк на `chat`.
  - Пустой/ошибочный ответ → повтор с задержкой.
  - Уже есть файлы → продолжение нумерации.

### 4) `experiments/run_experiment1_keywords.py`
- **Назначение**: Эксперимент 1 — извлечение ключевых слов (n‑граммы, YAKE, TextRank), сравнение `human` vs `AI`, метрики и графики.
- **Вход**: пути к корпусам (по 15 doc/тему для human и синтетики), параметры топ‑k и т.д.
- **Выход**: `results/experiment1/experiment1_report.md`, графики (diversity, top keywords, метрики).
- **Основные элементы**:
  - Предобработка и n‑gram извлечение (1-3)
  - YAKE корректно возвращает сами ключевые слова
  - Визуализации: бар‑чарты Jaccard/F1/P/R, топ-ключевые и диверсификация
- **Пример**:
```bash
python experiments/run_experiment1_keywords.py \
  --human_root data/human \
  --ai_root data/ai \
  --out_dir results/experiment1
```

- **Параметры и обоснование**:
  - `--human_root`, `--ai_root` — базовые директории с подпапками тем.
  - Внутренние: топ‑k ключевых слов, диапазоны n‑грамм (1–3) — охватывают частотные и устойчивые словосочетания.

- **Функции/логика**:
  - Предобработка: нормализация, токенизация, лемматизация, стоп‑слова.
  - Извлечение: n‑граммы TF‑IDF, YAKE (список строк), TextRank.
  - Метрики пересечения human vs AI: Jaccard, Precision/Recall/F1@k.
  - Визуализации: сравнительные бар‑чарты и графики диверсификации.

- **Краевые случаи**:
  - Пустые папки/файлы → пропуск с логом.
  - YAKE возвращал (kw, score) — учтено: берём только `kw`.

### 5) `experiments/run_experiment2_bert.py`
- **Назначение**: Эксперимент 2 — эмбеддинги (BERT/ALBERT/RoBERTa/MiniLM) + MLP классификатор (детекция AI‑текстов).
- **Вход**: корпуса human/AI, выбор моделей, параметры обучения/валидации.
- **Выход**: `results/experiment2/experiment2_report.md`, `classification_metrics.png`, `roc_curves.png`, `confusion_matrices.png`, сериализованные результаты.
- **Особенности**:
  - Кросс‑валидация и тест‑сплиты
  - Исключение несериализуемых объектов при сохранении JSON
- **Пример**:
```bash
python experiments/run_experiment2_bert.py \
  --human_root data/human \
  --ai_roots data/ai/llama data/ai/qwen data/ai/deepseek \
  --out_dir results/experiment2
```

- **Параметры и обоснование**:
  - Состав множеств AI‑корпусов (по моделям) — для межмодельного сравнения.
  - Выбор эмбеддингов (BERT, RoBERTa, ALBERT, MiniLM) — спектр размер/качество.
  - MLP как базовый нелинейный классификатор над эмбеддингами.

- **Функции/логика**:
  - Экстракция sentence‑эмбеддингов.
  - Тренировка/валидация (кросс‑валидация), финальный тест.
  - Сохранение метрик, ROC, матриц ошибок; сериализация результатов без моделей.

- **Краевые случаи**:
  - Несериализуемые объекты (np.int64) → явные `int()` при JSON‑дампе.

### 6) `experiments/run_additional_analysis.py`
- **Назначение**: Дополнительный анализ текстов — структура предложений, лексическое разнообразие (TTR), коннекторы, повторы, тональность.
- **Вход**: пути к корпусам.
- **Выход**: отчёт и графики в `results/additional_analysis/`.
- **Особенности**: устойчивость к отсутствию NLTK ресурсов (fallback'и).
- **Пример**:
```bash
python experiments/run_additional_analysis.py \
  --human_root data/human \
  --ai_root data/ai \
  --out_dir results/additional_analysis
```

- **Параметры и обоснование**:
  - Те же директории, что и в эксп. 1–2, для согласованного сравнения.
  - Доп. метрики: TTR, распределения длин, коннекторы, повторы, тональность — помогают интерпретировать поведение моделей.

- **Функции/логика**:
  - Надёжные фолбэки, если NLTK ресурсы отсутствуют.
  - Сводные графики и сравнительные диаграммы по моделям.

- **Краевые случаи**:
  - Нераспознанные символы/кодировка — очистка и пропуск проблемных документов.

### 7) `experiments/train_detect_ai.py`
- **Назначение**: Тренировка детектора (логрег/MLP) на заранее извлечённых признаках (ngrams/keywords и др.).
- **Вход**: директории с `features.csv` для human и AI‑корпусов.
- **Выход**: метрики в `experiments/detector_results/`.
- **Основные флаги**:
  - `--human_features` (dir)
  - `--ai_features` (one or many dirs)
  - `--out_root` (dir)
  - `--model` (`logreg` | `mlp`)
- **Пример**:
```bash
python experiments/train_detect_ai.py \
  --human_features experiments/features/human \
  --ai_features experiments/features/llama experiments/features/qwen experiments/features/deepseek \
  --out_root experiments/detector_results \
  --model mlp
```

- **Параметры и обоснование**:
  - Раздельные директории признаков по источникам — гибкая комбинация.
  - `--model`=`logreg|mlp` — линейная база vs простая нелинейность.

- **Функции/логика**:
  - Загрузка `features.csv`, унификация колонок, объединение датасетов.
  - Тренировка выбранной модели, сохранение метрик по парам и суммарно.

- **Краевые случаи**:
  - Разные наборы фич → приведение к пересечению/заполнение пропусков.

### 8) `experiments/arxiv_collector.py`
- **Назначение**: Класс‑обёртка для arXiv API, возвращает `pandas.DataFrame` с полями (`title`, `abstract`, `categories`, `published`, ...).
- **Использование**: импортируется в сборщиках/скриптах выгрузки, чтобы получить качественные CSV.

- **Функции/логика (типично)**:
  - Метод `fetch(query, max_results, start)` — запрос и сбор результатов с пагинацией.
  - Метод `to_dataframe(entries)` — нормализация, очистка HTML/TeX.
  - Обработка сетевых ошибок с повтором.

### 9) `experiments/utils.py`
- **Назначение**: Вспомогательные функции (загрузка текстов, нормализация путей, утилиты для визуализаций/метрик — по месту использования).

- **Функции (примерно)**:
  - `load_corpus(dir)` — рекурсивная загрузка `.txt` с безопасной кодировкой.
  - `ensure_dir(path)` — гарантирует наличие каталога.
  - Метрики/рисовалки, используемые в отчётах.

### 10) `experiments/make_report.py`
- **Назначение**: Склейка ключевых артефактов (метрики, графики) в удобный Markdown отчёт/сводку.
- **Вход/Выход**: зависит от содержимого `results/` и целей отчёта.

- **Логика**:
  - Чтение JSON/CSV метрик, вставка ссылок на графики, формирование оглавления.
  - Стабильные пути и относительные ссылки для GitHub‑рендера.

### Рекомендации
- Храните большие модели/артефакты вне Git (см. `.gitignore`).
- Для генерации синтетики предпочтительнее указывать `--mode auto`: скрипт сам подберёт поддерживаемый режим API.
- Следите за версиями Python/библиотек согласно `requirements.txt`.


