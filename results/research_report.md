# Отчет по исследованию: Детекция синтетических научных документов на основе ключевых слов и семантических признаков

## Оглавление

1. [Введение](#введение)
2. [Цели и задачи исследования](#цели-и-задачи-исследования)
3. [Методы извлечения ключевых слов](#методы-извлечения-ключевых-слов)
4. [Методы детекции синтетических текстов](#методы-детекции-синтетических-текстов)
5. [Экспериментальная часть](#экспериментальная-часть)
6. [Результаты и анализ](#результаты-и-анализ)
7. [Выводы](#выводы)
8. [Заключение](#заключение)

---

## Введение

Проблема распознавания синтетических текстов, сгенерированных большими языковыми моделями (LLM), становится все более актуальной в эпоху развития генеративных AI-систем. Особую важность эта задача приобретает в контексте научных документов, где подлинность и авторство имеют критическое значение.

**Гипотеза исследования**: Различия в использовании ключевых слов, лексико-стилистических признаках и семантических представлениях между человеческими и AI-сгенерированными научными текстами позволяют эффективно детектировать синтетические документы.

### Актуальность исследования

- **Академическая честность**: Необходимость выявления AI-сгенерированных текстов в научных публикациях
- **Автоматизация**: Разработка инструментов для автоматической проверки подлинности документов
- **Масштабируемость**: Обработка больших объемов документов с использованием различных признаков
- **Интерпретируемость**: Понимание того, какие признаки наиболее эффективны для детекции

---

## Цели и задачи исследования

### Цель
Исследовать эффективность использования ключевых слов, лексико-стилистических признаков и семантических эмбеддингов для детекции AI-сгенерированных научных документов.

### Задачи

1. **Анализ методов извлечения ключевых слов**
   - Сравнение статистических методов (TF-IDF, YAKE)
   - Сравнение графовых методов (TextRank)
   - Оценка различий в ключевых словах между HUMAN и AI текстами

2. **Исследование лексико-стилистических признаков**
   - Анализ частоты вводных/связующих слов (connectives)
   - Исследование метрик лексического разнообразия (TTR, Zipf, Self-BLEU)
   - Оценка структурных признаков (длина предложений, когерентность)

3. **Семантический анализ для детекции**
   - Применение различных эмбеддинговых моделей (BERT, RoBERTa, ALBERT, E5)
   - Классификация HUMAN vs AI с использованием эмбеддингов
   - Сравнение эффективности различных классификаторов

4. **Настройка методов на Inspec**
   - Подбор оптимальных параметров для извлечения ключевых слов
   - Оценка качества извлечения на тестовом датасете

---

## Методы извлечения ключевых слов

### 1. TF-IDF (Term Frequency-Inverse Document Frequency)

**Принцип работы:**
- Взвешивает важность термина в документе относительно всей коллекции
- Формула: `TF-IDF(t,d) = TF(t,d) × IDF(t)`
- Использует n-граммы (1-3 граммы) для извлечения фразовых ключевых слов
- В нашем исследовании: ngram_range=(1,2), min_df=1, max_df=0.9, max_features=8000

**Преимущества:**
- Учитывает частоту терминов в коллекции
- Быстро работает на больших датасетах
- Хорошо работает для технических текстов

**Недостатки:**
- Требует обучения на коллекции документов
- Не учитывает семантические связи

### 2. YAKE (Yet Another Keyword Extractor)

**Принцип работы:**
- Статистический метод без обучения
- Использует локальные признаки текста:
  - Частота термина
  - Позиция первого вхождения
  - Регистр букв
  - Разнообразие контекста
  - Дисперсия по предложениям
- В нашем исследовании: n=3, dedup_lim=0.8

**Преимущества:**
- Не требует обучения
- Быстрый и устойчивый
- Хорошо работает на разных языках

**Недостатки:**
- Может пропускать важные термины с низкой частотой

### 3. TextRank

**Принцип работы:**
- Строит граф слов на основе совместного появления в окне
- Применяет алгоритм PageRank для ранжирования слов
- Выбирает топ-K наиболее важных слов
- В нашем исследовании: ratio=0.2

**Преимущества:**
- Учитывает связи между словами
- Хорошо работает для связных текстов
- Стабильные результаты для разных значений K

**Недостатки:**
- Требует больше вычислительных ресурсов
- Чувствителен к размеру окна

---

## Методы детекции синтетических текстов

### 1. Лексико-стилистические признаки

#### Метрики пересечения ключевых слов

- **Jaccard Index**: `J(A,B) = |A∩B| / |A∪B|`
  - Измеряет сходство наборов ключевых слов
  - Значения 0.05-0.28 указывают на умеренные различия в наших экспериментах

- **Overlap Human/Synthetic**: `|A∩B| / |A|` и `|A∩B| / |B|`
  - Показывает долю пересечения относительно каждого набора
  - **Overlap Human**: какая доля человеческих ключевых слов найдена в синтетических
  - **Overlap Synthetic**: какая доля синтетических ключевых слов найдена в человеческих
  - Эти метрики могут различаться, показывая асимметрию в покрытии наборов
  - Например, если Overlap Synthetic > Overlap Human, это означает, что синтетические тексты содержат больше уникальных ключевых слов

- **Harmonic Mean**: `2·OH·OS / (OH+OS)`
  - Балансирует две метрики overlap
  - Учитывает асимметрию между наборами

#### Частота вводных слов (Connectives)

- **Connectives per 1000 words**: Частота дискурсивных коннекторов на 1000 слов
- Используется словарь из 96 коннекторов (PDTB-style)
- Метрики: AUC, оптимальный порог (Юден), Accuracy@threshold

#### Дополнительные метрики

- **TTR (Type-Token Ratio)**: `|уникальных токенов| / |всех токенов|`
- **Zipf slope/R²**: Наклон и R² при регрессии log(freq) ~ a + b·log(rank)
- **Self-BLEU-1**: Средняя униграмная прецизионная похожесть документа на остальные
- **Coherence TF-IDF**: Средняя косинусная близость соседних предложений
- **Sentence length mean/std**: Средняя длина и стандартное отклонение предложений
- **Gzip ratio**: Степень сжатия текста (выше → более повторяемо)

### 2. Семантические эмбеддинги

#### Модели эмбеддингов

1. **bert-base-uncased**: Классическая BERT модель (768 dim)
2. **roberta-base**: RoBERTa модель (768 dim)
3. **albert-base-v2**: ALBERT модель (768 dim)
4. **sentence-transformers/all-mpnet-base-v2**: MPNet модель (768 dim)
5. **intfloat/e5-large-v2**: E5 модель (1024 dim)

#### Классификаторы

- **MLP (Multi-Layer Perceptron)**: Полносвязная нейронная сеть
- **Logistic Regression**: Линейная регрессия с логистической функцией
- **Linear SVM**: Линейный метод опорных векторов

#### Метрики классификации

- **Accuracy**: `(TP+TN)/(TP+FP+TN+FN)` - доля верно классифицированных документов
- **Precision (AI)**: `TP/(TP+FP)` - сколько из предсказанных AI действительно AI
- **Recall (AI)**: `TP/(TP+FN)` - сколько из всех AI обнаружено
- **F1-score**: `2PR/(P+R)` - гармоническое среднее Precision и Recall
- **ROC AUC**: Площадь под ROC-кривой (1.0 = идеальная разделимость)
- **CV Mean/Std**: Среднее и стандартное отклонение Accuracy на 5-fold cross-validation

---

## Экспериментальная часть

### Датасеты

#### 1. Человеческие документы (HUMAN)

- **Источник**: arXiv (через API)
- **Категории**: 
  - Text Mining (TM): 50 документов
  - Information Retrieval (IR): 50 документов
- **Всего**: 100 документов
- **Формат**: TXT файлы с полями Title и Abstract

#### 2. Синтетические документы (AI)

- **Модели генерации**:
  - Qwen (Qwen2.5-72B-Instruct): 100 документов (50 TM + 50 IR)
  - DeepSeek (DeepSeek-V3/R1): 100 документов (50 TM + 50 IR)
  - GPT-OSS-20B: 100 документов (50 TM + 50 IR)
- **Всего**: 300 синтетических документов
- **Метод генерации**: Hugging Face Inference API
- **Промпты**: На основе заголовков реальных статей из arXiv

#### 3. Inspec (для настройки параметров)

- **Назначение**: Оптимизация параметров методов извлечения ключевых слов
- **Формат**: train/dev/test splits (если доступен)
- **Gold стандарт**: Ручные ключевые слова

### Метрики оценки

#### Для извлечения ключевых слов:
- **Precision@K**: Доля правильно извлеченных ключевых слов среди первых K
- **Recall@K**: Доля найденных ключевых слов от общего количества золотых
- **F1@K**: Гармоническое среднее precision и recall
- **Jaccard(top-K)**: `|Pred∩Gold| / |Pred∪Gold|`

#### Для детекции:
- **Jaccard Index**: Сходство наборов ключевых слов между HUMAN и AI
- **Overlap Human/Synthetic**: Доля пересечения относительно каждого набора
- **Harmonic Mean**: Балансированная метрика пересечения
- **Connectives AUC**: Разделимость по частоте вводных слов
- **Classification Accuracy/AUC**: Точность классификации HUMAN vs AI

### Экспериментальная установка

#### Эксперимент 1: Лексико-стилистический анализ

- **Корпуса**: 100 HUMAN (50 TM + 50 IR) против 100 AI на каждую модель
- **Методы**: TF-IDF n-граммы, YAKE, TextRank
- **Метрики**: Jaccard, Overlap Human/Synthetic, Harmonic Mean
- **Дополнительно**: Connectives per 1000, TF-IDF cosine similarity между центроидами

#### Эксперимент 2: Семантический анализ

- **Корпуса**: 100 HUMAN против 100 AI на каждую модель
- **Эмбеддинги**: bert-base-uncased, roberta-base, albert-base-v2, all-mpnet-base-v2, e5-large-v2
- **Классификаторы**: MLP, Logistic Regression, Linear SVM
- **Валидация**: Train/test split + 5-fold cross-validation

#### Эксперимент 3: Настройка на Inspec

- **Цель**: Подбор оптимальных параметров для извлечения ключевых слов
- **Методы**: TF-IDF, YAKE, TextRank
- **Критерий**: F1@10 на dev split
- **Применение**: Использование лучших параметров для сравнения HUMAN vs AI

---

## Результаты и анализ

### Эксперимент 1: Лексико-стилистический анализ

#### Результаты по моделям синтетики

**QWEN (100 HUMAN vs 100 AI):**

| Метод | Jaccard | Overlap H | Overlap S | Harmonic |
|-------|---------|-----------|-----------|----------|
| NGRAMS | 0.252 | 0.366 | 0.448 | 0.403 |
| YAKE | 0.055 | 0.101 | 0.109 | 0.105 |
| TEXTRANK | 0.216 | 0.398 | 0.321 | 0.356 |

- Connectives per 1000 words: HUMAN=15.75, QWEN=14.83
- Connectives detection: AUC=0.503, Threshold <= 7.71, Acc@thr=0.420
- TF-IDF centroid cosine similarity: 0.693

**DEEPSEEK (100 HUMAN vs 100 AI):**

| Метод | Jaccard | Overlap H | Overlap S | Harmonic |
|-------|---------|-----------|-----------|----------|
| NGRAMS | 0.281 | 0.396 | 0.492 | 0.439 |
| YAKE | 0.066 | 0.117 | 0.133 | 0.125 |
| TEXTRANK | 0.229 | 0.474 | 0.306 | 0.372 |

- Connectives per 1000 words: HUMAN=15.75, DEEPSEEK=14.46
- Connectives detection: AUC=0.491, Threshold <= 8.50, Acc@thr=0.395
- TF-IDF centroid cosine similarity: 0.740

**GPTOSS (100 HUMAN vs 100 AI):**

| Метод | Jaccard | Overlap H | Overlap S | Harmonic |
|-------|---------|-----------|-----------|----------|
| NGRAMS | 0.208 | 0.336 | 0.352 | 0.344 |
| YAKE | 0.031 | 0.061 | 0.061 | 0.061 |
| TEXTRANK | 0.221 | 0.374 | 0.352 | 0.363 |

- Connectives per 1000 words: HUMAN=15.75, GPTOSS=11.32
- Connectives detection: AUC=0.387, Threshold <= inf, Acc@thr=0.500
- TF-IDF centroid cosine similarity: 0.668

#### Дополнительные метрики (средние значения)

| Метрика | HUMAN | AI (среднее) |
|---------|-------|--------------|
| TTR | 0.185 | 0.128 |
| Zipf slope | -0.988 | -1.133 |
| Zipf R² | 0.965 | 0.958 |
| Self-BLEU1 | 0.783 | 0.849 |
| Coherence TF-IDF | 0.036 | 0.028 |
| Sentence length mean | 24.33 | 26.92 |
| Sentence length std | 11.30 | 10.21 |
| Gzip ratio | 2.86 | 3.36 |

#### Ключевые выводы:

1. **Умеренные различия в ключевых словах**:
   - Jaccard Index находится в диапазоне 0.05-0.28 (значительно ниже, чем ожидалось)
   - Overlap Human и Overlap Synthetic теперь различаются, что показывает асимметрию в покрытии наборов
   - Например, для NGRAMS: Overlap H = 0.34-0.40, Overlap S = 0.35-0.49 — синтетические тексты содержат больше уникальных ключевых слов, не встречающихся в человеческих
   - Это указывает на умеренное, но не радикальное различие в лексике
   - Только лексических признаков недостаточно для надежной детекции

2. **Небольшие различия в connectives**:
   - AI тексты показывают чуть более низкую частоту вводных слов
   - AUC для connectives detection низкий (0.39-0.50), что близко к случайному угадыванию
   - Это слабый признак, требует дополнения другими методами

3. **Умеренное TF-IDF сходство**:
   - Косинусное сходство центроидов 0.67-0.74
   - Различия есть, но не критичные
   - Подходит как вспомогательная фича

4. **Лексико-стилистические паттерны**:
   - AI тексты имеют более низкий TTR (меньше лексического разнообразия)
   - Выше Self-BLEU1 (более однотипные тексты)
   - Выше Gzip ratio (более повторяемы и сжимаемы)

### Эксперимент 2: Семантический анализ

#### Результаты по моделям синтетики

**QWEN (100 HUMAN vs 100 AI):**

Лучшие результаты:
- **roberta-base**: Accuracy=1.000, AUC=1.000 (MLP, LogReg, LinearSVM)
- **albert-base-v2**: Accuracy=1.000, AUC=1.000 (MLP)
- **bert-base-uncased**: Accuracy=0.925-0.975, AUC=0.978-1.000
- **e5-large-v2**: Accuracy=0.700-0.900, AUC=0.785-0.958
- **all-mpnet-base-v2**: Accuracy=0.575-0.775, AUC=0.627-0.853

**DEEPSEEK (100 HUMAN vs 100 AI):**

Лучшие результаты:
- **roberta-base**: Accuracy=1.000, AUC=1.000 (все классификаторы)
- **e5-large-v2**: Accuracy=1.000, AUC=1.000 (все классификаторы)
- **albert-base-v2**: Accuracy=0.950-0.975, AUC=1.000
- **bert-base-uncased**: Accuracy=0.975-1.000, AUC=1.000

**GPTOSS (100 HUMAN vs 100 AI):**

Лучшие результаты:
- **roberta-base**: Accuracy=1.000, AUC=1.000 (все классификаторы)
- **albert-base-v2**: Accuracy=1.000, AUC=1.000 (все классификаторы)
- **e5-large-v2**: Accuracy=0.975-1.000, AUC=1.000
- **bert-base-uncased**: Accuracy=0.975-1.000, AUC=0.997-1.000

#### Сводная таблица лучших результатов

| Модель | Embedding | Классификатор | Accuracy | AUC | CV Mean | CV Std |
|--------|-----------|---------------|----------|-----|---------|--------|
| Qwen | roberta-base | MLP/LogReg/SVM | 1.000 | 1.000 | 1.000 | 0.000 |
| Qwen | albert-base-v2 | MLP | 1.000 | 1.000 | 0.975 | 0.036 |
| DeepSeek | roberta-base | MLP/LogReg/SVM | 1.000 | 1.000 | 1.000 | 0.000 |
| DeepSeek | e5-large-v2 | MLP/LogReg/SVM | 1.000 | 1.000 | 1.000 | 0.000 |
| GPTOSS | roberta-base | MLP/LogReg/SVM | 1.000 | 1.000 | 1.000 | 0.000 |
| GPTOSS | albert-base-v2 | MLP/LogReg/SVM | 1.000 | 1.000 | 0.975 | 0.023 |

#### Ключевые выводы:

1. **Практически идеальная разделимость**:
   - roberta-base и albert-base-v2 показывают Accuracy=1.000 и AUC=1.000
   - Это указывает на практически совершенное разделение HUMAN/AI в текущем датасете
   - Эмбеддинги улавливают семантические различия максимально эффективно

2. **Эффективность линейных классификаторов**:
   - Logistic Regression и Linear SVM показывают результаты, сопоставимые с MLP
   - На сильных эмбеддингах линейные разделители достаточны
   - Это упрощает практическое применение

3. **Различия между моделями эмбеддингов**:
   - roberta-base и albert-base-v2 — наиболее эффективные
   - e5-large-v2 показывает отличные результаты для DeepSeek и GPTOSS
   - all-mpnet-base-v2 на данном датасете показывает слабые результаты (возможна доменная несовместимость)

4. **Стабильность результатов**:
   - CV Mean близок к Accuracy на test set
   - Низкое CV Std (0.000-0.036) указывает на устойчивость результатов

### Эксперимент 3: Настройка на Inspec и сравнение HUMAN vs AI

#### Лучшие параметры (дефолтные, т.к. Inspec недоступен)

- **TF-IDF**: ngram_range=(1,2), min_df=1, max_df=0.9, max_features=8000
- **YAKE**: n=3, dedup=0.8
- **TextRank**: ratio=0.2

#### Сравнение ключевых слов HUMAN vs AI

**QWEN:**

| Метод | Jaccard | Overlap H | Overlap S | Harmonic |
|-------|---------|-----------|-----------|----------|
| TFIDF | 0.220 | 0.360 | 0.360 | 0.360 |
| YAKE | 0.190 | 0.320 | 0.320 | 0.320 |
| TEXTRANK | 0.266 | 0.420 | 0.420 | 0.420 |

**DEEPSEEK:**

| Метод | Jaccard | Overlap H | Overlap S | Harmonic |
|-------|---------|-----------|-----------|----------|
| TFIDF | 0.266 | 0.420 | 0.420 | 0.420 |
| YAKE | 0.205 | 0.340 | 0.340 | 0.340 |
| TEXTRANK | 0.351 | 0.520 | 0.520 | 0.520 |

**GPTOSS:**

| Метод | Jaccard | Overlap H | Overlap S | Harmonic |
|-------|---------|-----------|-----------|----------|
| TFIDF | 0.250 | 0.400 | 0.400 | 0.400 |
| YAKE | 0.136 | 0.240 | 0.240 | 0.240 |
| TEXTRANK | 0.299 | 0.460 | 0.460 | 0.460 |

#### Ключевые выводы:

1. **TextRank показывает наибольшие различия**:
   - Harmonic Mean достигает 0.42-0.52
   - Это указывает на более заметные различия при использовании графовых методов

2. **YAKE показывает наименьшие различия**:
   - Harmonic Mean 0.24-0.34
   - Возможно, YAKE извлекает более общие термины, общие для HUMAN и AI

3. **Сравнение с другими подходами**:
   - Лексические методы дают умеренные значения различий
   - Семантические эмбеддинги показывают существенно лучшую разделимость (AUC≈1.0)
   - Вывод: для детекции синтетики ключевые слова — вспомогательный канал

---

## Выводы

### Основные результаты исследования

1. **Семантические эмбеддинги — наиболее эффективный метод**:
   - roberta-base и albert-base-v2 показывают Accuracy=1.000 и AUC=1.000
   - Практически идеальная разделимость HUMAN/AI на текущем датасете
   - Линейные классификаторы (LogReg, LinearSVM) достаточны на сильных эмбеддингах

2. **Лексико-стилистические признаки дают слабые-умеренные сигналы**:
   - Jaccard/Harmonic в диапазоне 0.05-0.44 — более низкие значения, чем ожидалось
   - Overlap Human и Overlap Synthetic теперь различаются, показывая асимметрию: синтетические тексты содержат больше уникальных ключевых слов
   - Connectives detection показывает низкий AUC (0.39-0.50)
   - Эти признаки недостаточны для надежной детекции в одиночку
   - Рекомендуется использовать как часть ансамбля

3. **Оптимальная комбинация методов**:
   - Основной детектор: семантические эмбеддинги (roberta-base или e5-large-v2) + линейный классификатор
   - Вспомогательные признаки: Jaccard/Harmonic по ключевым словам, Connectives per 1000, TF-IDF cosine
   - Ансамбль: Score = α·(semantic_prob) + β·(1−Harmonic) + γ·|ΔConnectives| + δ·(1−Cosine)

4. **Влияние модели синтетики**:
   - Все три модели (Qwen, DeepSeek, GPTOSS) успешно детектируются семантическими методами
   - Лексические различия варьируются: DeepSeek показывает наибольшие различия по NGRAMS (Overlap H=0.396, Overlap S=0.492)
   - YAKE показывает наименьшие различия (Jaccard 0.03-0.07), что указывает на извлечение более общих терминов
   - GPTOSS показывает наименьшую частоту connectives (11.32 vs 15.75 у HUMAN)

### Практические рекомендации

1. **Для максимальной точности**: 
   - Используйте roberta-base или albert-base-v2 эмбеддинги
   - Классификатор: Logistic Regression или Linear SVM
   - Добавьте лексико-стилистические признаки для устойчивости

2. **Для скорости и простоты**:
   - Используйте e5-large-v2 (если доступен) или roberta-base
   - Линейный классификатор (LogReg или LinearSVM)
   - Минимальный набор признаков: только эмбеддинги

3. **Для интерпретируемости**:
   - Комбинируйте семантические и лексические признаки
   - Анализируйте различия в ключевых словах и connectives
   - Используйте ансамбль для повышения уверенности

### Ограничения исследования

1. **Размер выборки**: 
   - 100 HUMAN и 100 AI на модель — относительно небольшая выборка
   - Результаты могут варьироваться на других доменах и темах

2. **Доменная специфичность**:
   - Эксперименты проводились на научных текстах (Text Mining, Information Retrieval)
   - Результаты могут отличаться для других типов текстов

3. **Модели синтетики**:
   - Тестировались только три модели (Qwen, DeepSeek, GPTOSS)
   - Другие модели могут показывать другие паттерны

4. **Inspec недоступен**:
   - Настройка параметров проводилась на дефолтных значениях
   - Реальные результаты на Inspec могут улучшить качество извлечения ключевых слов

### Возможные улучшения

1. **Расширение данных**:
   - Увеличение выборки до 500+ документов на класс
   - Добавление других тем и доменов
   - Включение других моделей синтетики (Llama, GLM, GPT-4)

2. **Улучшение методов**:
   - Настройка параметров на Inspec (когда доступен)
   - Тестирование других эмбеддинговых моделей (GTE, Jina, BGE)
   - Эксперименты с ансамблями классификаторов

3. **Дополнительные признаки**:
   - Анализ синтаксических паттернов
   - Исследование ритмических признаков
   - Анализ распределения частей речи

---

## Заключение

Проведенное исследование подтвердило эффективность использования семантических эмбеддингов для детекции AI-сгенерированных научных документов. Семантические методы показывают практически идеальную разделимость (Accuracy=1.000, AUC=1.000), что делает их предпочтительными для практической детекции.

**Главный результат**: Семантические эмбеддинги (особенно roberta-base и albert-base-v2) в сочетании с линейными классификаторами обеспечивают практически совершенную детекцию синтетических текстов, в то время как лексико-стилистические признаки (ключевые слова, connectives) дают слабые-умеренные сигналы и должны использоваться как вспомогательные признаки в ансамблевой системе.

Лексико-стилистические методы (анализ ключевых слов, частоты connectives) показывают лишь умеренные различия между HUMAN и AI текстами. Эти признаки полезны для интерпретации и дополнительной уверенности, но недостаточны для надежной детекции в одиночку.

**Практическая рекомендация**: Для детекции синтетических научных документов использовать комбинацию:
1. Основной детектор: семантические эмбеддинги (roberta-base или e5-large-v2) + линейный классификатор
2. Вспомогательные признаки: анализ ключевых слов (TextRank Harmonic), частота connectives, TF-IDF cosine similarity
3. Ансамблевая система: взвешенная комбинация всех признаков

Результаты исследования могут быть использованы в системах проверки академической честности, автоматической модерации научных публикаций и других задачах, связанных с детекцией синтетических текстов.

---

## Пояснения к реализации

### Архитектура системы

Система построена модульно и состоит из следующих компонентов:

#### 1. Эксперимент 1: Лексико-стилистический анализ (`experiments/run_experiment1_per_model.py`)

**Функции:**
- Извлечение ключевых слов: TF-IDF, YAKE, TextRank
- Подсчет метрик пересечения: Jaccard, Overlap, Harmonic Mean
- Анализ connectives: частота на 1000 слов, детекция с порогом
- Дополнительные метрики: TTR, Zipf, Self-BLEU, Coherence, Gzip ratio

**Пример использования:**
```bash
python3 experiments/run_experiment1_per_model.py \
    --output_dir results/experiment1_per_model \
    --human_per_topic 50 --docs_per_model 100 \
    --connectives_path resources/pdtb_connectives_en.txt
```

#### 2. Эксперимент 2: Семантический анализ (`experiments/run_experiment2_bert.py`)

**Функции:**
- Извлечение эмбеддингов: BERT, RoBERTa, ALBERT, MPNet, E5
- Классификация: MLP, Logistic Regression, Linear SVM
- Валидация: Train/test split + 5-fold cross-validation

**Пример использования:**
```bash
python3 experiments/run_experiment2_bert.py \
    --output_dir results/experiment2 \
    --docs_per_topic 50 --pooling mean
```

#### 3. Эксперимент 3: Настройка на Inspec (`experiments/run_experiment3_inspec.py`)

**Функции:**
- Загрузка Inspec (если доступен)
- Grid search параметров для TF-IDF, YAKE, TextRank
- Оценка на test split (Precision@K, Recall@K, F1@K)
- Применение лучших параметров к HUMAN vs AI корпусам

**Пример использования:**
```bash
python3 experiments/run_experiment3_inspec.py \
    --inspec_root data/inspec \
    --output_dir results/experiment3 --top_k 15
```

### Структура результатов

```
results/
├── experiment1_per_model/
│   ├── experiment1_per_model_report.md
│   ├── experiment1_per_model_results.json
│   ├── qwen_overlaps.png
│   ├── deepseek_overlaps.png
│   ├── gptoss_overlaps.png
│   └── *_connectives_cosine.png
├── experiment2/
│   ├── experiment2_report.md
│   ├── experiment2_results.json
│   ├── classification_metrics_*.png
│   ├── roc_curves_*.png
│   └── confusion_matrices_*.png
└── experiment3/
    ├── experiment3_report.md
    ├── experiment3_results.json
    └── inspec_f1_at10.png (если Inspec доступен)
```

### Используемые библиотеки

- **scikit-learn**: Классификация (SVM, Logistic Regression, MLP), векторизация (TF-IDF)
- **transformers**: Эмбеддинги BERT, RoBERTa, ALBERT
- **sentence-transformers**: Эмбеддинги MPNet, E5
- **yake**: YAKE экстрактор ключевых слов
- **summa**: TextRank экстрактор ключевых слов
- **matplotlib, seaborn**: Визуализация результатов
- **pandas, numpy**: Обработка данных
- **scipy**: Статистические вычисления

### Метрики и их интерпретация

**Jaccard Index (0.25-0.56)**: Умеренное пересечение наборов ключевых слов. Значения ближе к 0.5 указывают на заметные различия, но не радикальные.

**Harmonic Mean (0.24-0.56)**: Балансированная метрика пересечения. Выше 0.4 указывает на умеренные различия.

**Connectives AUC (0.39-0.50)**: Низкие значения, близкие к случайному угадыванию (0.5). Слабый признак для детекции.

**Classification Accuracy (1.000)**: Идеальная классификация — все документы правильно разделены на HUMAN и AI.

**ROC AUC (1.000)**: Идеальная разделимость классов — модель полностью разделяет HUMAN и AI тексты.

---

## Инструкции по воспроизведению результатов

### Требования

- Python 3.9+
- Все зависимости из `requirements.txt`
- Hugging Face token (для генерации синтетических текстов)

### Установка зависимостей

```bash
pip install -r requirements.txt
```

### Подготовка данных

1. **Человеческие документы** (уже собраны):
   - `data/human/text_mining/` — 50 документов
   - `data/human/information_retrieval/` — 50 документов

2. **Синтетические документы** (уже сгенерированы):
   - `data/ai/qwen_api_auto/text_mining_full/` — 50 документов
   - `data/ai/qwen_api/ir/` — 50 документов
   - `data/ai/deepseek_api_auto/text_mining_full/` — 50 документов
   - `data/ai/deepseek_api/ir/` — 50 документов
   - `data/ai/gptoss_api/text_mining_full/` — 50 документов
   - `data/ai/gptoss_api/ir/` — 50 документов

3. **Словарь connectives** (создан):
   - `resources/pdtb_connectives_en.txt` — 96 коннекторов

### Запуск экспериментов

#### 1. Эксперимент 1: Лексико-стилистический анализ

```bash
python3 experiments/run_experiment1_per_model.py \
    --output_dir results/experiment1_per_model \
    --human_per_topic 50 --docs_per_model 100 \
    --connectives_path resources/pdtb_connectives_en.txt
```

**Результаты**: `results/experiment1_per_model/experiment1_per_model_report.md`

#### 2. Эксперимент 2: Семантический анализ

```bash
python3 experiments/run_experiment2_bert.py \
    --output_dir results/experiment2 \
    --docs_per_topic 50 --pooling mean
```

**Результаты**: `results/experiment2/experiment2_report.md`

#### 3. Эксперимент 3: Настройка на Inspec

```bash
python3 experiments/run_experiment3_inspec.py \
    --inspec_root data/inspec \
    --output_dir results/experiment3 --top_k 15
```

**Результаты**: `results/experiment3/experiment3_report.md`

---

## Сводная таблица результатов

### Сравнение методов детекции

| Метод | Модель | Accuracy | AUC | Рекомендация |
|-------|--------|----------|-----|--------------|
| **Семантический (roberta-base)** | Qwen/DeepSeek/GPTOSS | **1.000** | **1.000** | **Основной детектор** |
| **Семантический (albert-base-v2)** | Qwen/DeepSeek/GPTOSS | **1.000** | **1.000** | **Основной детектор** |
| **Семантический (e5-large-v2)** | DeepSeek/GPTOSS | **1.000** | **1.000** | **Альтернатива** |
| Лексический (TextRank Harmonic) | Qwen/DeepSeek/GPTOSS | - | - | Вспомогательный признак |
| Лексический (Connectives AUC) | Qwen/DeepSeek/GPTOSS | - | 0.39-0.50 | Слабый признак |

### Сравнение различий в ключевых словах

| Модель | Метод | Jaccard | Overlap H | Overlap S | Harmonic | Интерпретация |
|--------|-------|---------|-----------|-----------|----------|---------------|
| Qwen | NGRAMS | 0.252 | 0.366 | 0.448 | 0.403 | Умеренные различия, асимметрия |
| Qwen | TextRank | 0.216 | 0.398 | 0.321 | 0.356 | Умеренные различия |
| DeepSeek | NGRAMS | 0.281 | 0.396 | 0.492 | 0.439 | Более заметные различия, асимметрия |
| DeepSeek | TextRank | 0.229 | 0.474 | 0.306 | 0.372 | Умеренные различия, асимметрия |
| GPTOSS | NGRAMS | 0.208 | 0.336 | 0.352 | 0.344 | Умеренные различия |

**Вывод**: Лексические различия умеренные, недостаточны для надежной детекции в одиночку. Overlap Human и Overlap Synthetic различаются, показывая, что синтетические тексты содержат больше уникальных ключевых слов, не встречающихся в человеческих.

---

## Список литературы

1. Salton, G., & McGill, M. J. (1986). Introduction to modern information retrieval.
2. Campos, R., Mangaravite, V., Pasquali, A., et al. (2020). YAKE! Keyword extraction from single documents using multiple local features.
3. Mihalcea, R., & Tarau, P. (2004). TextRank: Bringing order into text.
4. Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.
5. Liu, Y., Ott, M., Goyal, N., et al. (2019). RoBERTa: A Robustly Optimized BERT Pretraining Approach.
6. Lan, Z., Chen, M., Goodman, S., et al. (2020). ALBERT: A Lite BERT for Self-supervised Learning of Language Representations.
7. Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.
8. Wang, L., Yang, N., Huang, X., et al. (2022). Text Embeddings by Weakly-Supervised Contrastive Pre-training.
9. ArXiv Dataset: https://arxiv.org/
10. Penn Discourse Treebank (PDTB): https://www.seas.upenn.edu/~pdtb/

---

*Отчет подготовлен на основе результатов трех экспериментов: лексико-стилистический анализ (100 HUMAN vs 100 AI на модель), семантический анализ (100 HUMAN vs 100 AI на модель), настройка на Inspec и сравнение ключевых слов.*

**Дата создания**: 2024  
**Автор**: Дипломная работа  
**Тема**: Детекция синтетических научных документов на основе ключевых слов и семантических признаков

