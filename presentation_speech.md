# Речь для презентации научно-исследовательской работы
## Тема: Разработка метода автоматического определения различий между авторскими и сгенерированными текстами

---

## Введение (1-1.5 минуты)

Добрый день! Сегодня я представляю результаты научно-исследовательской работы, посвященной разработке методов автоматического определения различий между авторскими и сгенерированными большими языковыми моделями текстами.

Актуальность данной темы не вызывает сомнений. С развитием больших языковых моделей, таких как Qwen, DeepSeek, GPT и других, и увеличением их доступности, мы сталкиваемся с серьезной проблемой: современные системы генерации текста могут создавать материалы, которые визуально практически неотличимы от написанных человеком. 

Детекция сгенерированных искусственным интеллектом текстов становится критически важным этапом обеспечения академической честности. Это позволяет проверять подлинность работ, выявлять случаи плагиата и оценивать качество контента, создаваемого с помощью искусственного интеллекта. 

Если рассматривать проблему шире, понимание различий между текстами на естественном языке и сгенерированными текстами позволит выявлять фейковые новости, обнаруживать боты в социальных сетях, а также анализировать особенности функционирования больших языковых моделей.

Особенно важно акцентировать внимание на этой проблеме в контексте научных работ, где подлинность и авторство имеют приоритетное значение для всего научного сообщества.

---

## Цели и задачи (30 секунд - 1 минута)

Основная цель нашей работы заключается в разработке комплексного метода автоматического определения различий между авторскими и сгенерированными текстами на основе анализа ключевых слов и лексико-стилистических признаков.

Гипотеза исследования заключается в том, что различия в использовании ключевых слов и лексико-стилистических признаках между человеческими и синтетическими научными текстами позволяют эффективно детектировать сгенерированные ИИ документы.

В рамках работы были реализованы методы детекции, проверяющие эффективность различных подходов к распознаванию синтетических текстов, их точность и надежность.

---

## Методология (1.5-2 минуты)

### Подготовка данных

Для проведения исследования был сформирован корпус из 100 авторских научных документов с сайта ArXiv.org по тематикам "Information Retrieval" и "Text Mining" — по 50 документов на каждую тематику. ArXiv.org был выбран как крупнейшее хранилище научных публикаций с открытым доступом, содержащее высококачественные авторские тексты.

Синтетические тексты генерировались с помощью трех больших языковых моделей: Qwen, DeepSeek и GPT-OSS. Выбор этих моделей был обусловлен их доступностью, высоким качеством генерации и разнообразием архитектурных подходов. Для каждой модели было сгенерировано по 100 документов — 50 по теме "Text Mining" и 50 по "Information Retrieval", всего 300 синтетических документов.

Промпты для генерации формировались на основе заголовков реальных статей из ArXiv.org, что обеспечивало соответствие тематики синтетических текстов авторским текстам и усиливало схожесть между ними для более точной оценки методов детекции.

### Методы извлечения ключевых слов

В работе использовались три метода извлечения ключевых слов:

**Первый метод** — TF-IDF n-граммы, расширение классического метода TF-IDF для работы с последовательностями слов. Метод создает матрицу для всех n-грамм в коллекции документов и выбирает те, которые имеют максимальные TF-IDF оценки. Использовались n-граммы в диапазоне от 1 до 3, что позволяет извлекать как отдельные слова, так и фразы.

**Второй метод** — YAKE, статистический метод для извлечения ключевых слов без обучения. Он использует локальные признаки текста: частоту термина, позицию вхождения, регистр букв, разнообразие контекста. Преимуществами YAKE являются отсутствие необходимости в обучении и хорошая производительность на текстах различных жанров.

**Третий метод** — TextRank, графовый метод, основанный на алгоритме PageRank. Он формирует граф слов по их совместному появлению в тексте и ранжирует вершины графа по важности, выбирая наиболее значимые слова в качестве ключевых.

### Методы детекции

Были реализованы два основных подхода к детекции:

**Первый подход** — анализ лексико-стилистических признаков. Он включает анализ частоты дискурсивных коннекторов — слов и фраз, связывающих части текста, таких как "however", "moreover", "in contrast". Также анализировались метрики лексического разнообразия, структуры предложений и повторяемости фраз.

**Второй подход** — классификация на основе ключевых слов. Для каждого документа создавался бинарный вектор признаков, где каждый элемент указывает на присутствие или отсутствие соответствующего ключевого слова. На этих векторах обучались классификаторы: логистическая регрессия, линейный метод опорных векторов и случайный лес.

Количество ключевых слов варьировалось от 5 до 50 для оценки влияния этого параметра на качество классификации.

---

## Основные результаты (2-2.5 минуты)

### Эксперимент 1: Лексико-стилистический анализ

Первый эксперимент был посвящен сравнению ключевых слов между авторскими и синтетическими текстами.

Метрики пересечения ключевых слов показали интересные результаты. Индекс Жаккара, показывающий сходство наборов ключевых слов, оказался низким для всех методов: для YAKE — всего 0.026, для TF-IDF n-грамм — 0.155, для TextRank — 0.179. Это означает, что наборы ключевых слов в авторских и синтетических текстах существенно различаются, что является хорошим признаком для детекции.

Особенно интересна асимметрия метрик Overlap: Overlap Synthetic превышает Overlap Human для всех методов. Это указывает на то, что синтетические тексты содержат больше уникальных терминов, не встречающихся в авторских текстах, тогда как авторские тексты сохраняют предметно-специфичные маркеры.

Анализ лексического разнообразия показал, что авторские тексты имеют более высокий показатель TTR — от 0.512 до 0.529, по сравнению с синтетическими — от 0.406 до 0.414. Это указывает на более богатый словарь авторских текстов.

Однако анализ дискурсивных коннекторов показал, что метрика Connectives AUC имеет низкие значения — от 0.39 до 0.5, что близко к случайному угадыванию. Это означает, что данный признак сам по себе не обеспечивает надежную детекцию, но может быть полезен в комбинации с другими методами.

Семантический анализ показал умеренное сходство между авторскими и синтетическими текстами — косинусное сходство составляет 0.67-0.74. Метрика Self-BLEU-1 показала, что синтетические тексты более однотипны и повторяемы — 0.849 против 0.783 у авторских.

### Эксперимент 2: Классификация на основе ключевых слов

Второй эксперимент показал высокую эффективность классификаторов на основе ключевых слов.

**Лучший результат** был достигнут при использовании метода YAKE в сочетании с линейным методом опорных векторов и количеством ключевых слов K=50: точность классификации составила **0.963**, что означает, что 96.3% документов были правильно классифицированы.

Также высокие результаты показала комбинация TF-IDF n-грамм с методом случайного леса при K=50: точность составила 0.950, а площадь под ROC-кривой — **0.997**, что указывает на почти идеальное разделение классов.

Важным наблюдением стало то, что качество классификации монотонно улучшалось с увеличением количества ключевых слов от 5 до 50. При малом количестве ключевых слов — менее 10 — точность была низкой, менее 0.85. Оптимальное значение K составило 50, что указывает на важность использования достаточного количества признаков для надежной классификации.

Результаты кросс-валидации показали стабильность методов с низкой вариативностью между фолдами, что подтверждает надежность разработанных методов и отсутствие переобучения.

---

## Выводы и перспективы (1 минута)

На основе проведенных экспериментов можно сделать следующие выводы:

**Во-первых**, метод на основе лексико-стилистического анализа помог выявить различия между авторскими и синтетическими текстами на структурном, лексическом и стилистическом уровнях. Эти признаки могут быть использованы в комбинации с другими методами как дополнительная информация.

**Во-вторых**, классификаторы на основе ключевых слов продемонстрировали высокую эффективность, достигая точности 96.3%. Метод показал монотонное улучшение качества с увеличением количества ключевых слов, достигая оптимальных результатов при K=50.

**В-третьих**, дискурсивные коннекторы показали низкую разделимость классов и не могут использоваться как основной метод детекции, но могут служить вспомогательным признаком.

### Сравнение с существующими подходами

Сравнение с существующими подходами показывает, что наша работа согласуется с выводами других исследований. Семантические эмбеддинги, как показывают работы других авторов, обеспечивают максимальную точность детекции. Классификаторы на ключевых словах, как показано в нашей работе, являются эффективным альтернативным методом, особенно для интерпретируемого и дешевого скрининга.

### Перспективы развития

Для дальнейшего улучшения методов детекции предлагается:

1. Расширение выборки и добавление других тематик для оценки обобщающей способности методов
2. Разработка многоуровневой системы детекции с комбинацией различных методов
3. Использование семантических эмбеддингов для более эффективного учета контекста и смысловой составляющей документов

Результаты исследования показывают, что разработанные методы детекции синтетических текстов эффективны и могут быть использованы в практических системах проверки академической честности.

---

## Заключение

В заключение хочу отметить, что задача детекции синтетических текстов становится все более актуальной в эпоху развития больших языковых моделей. Проведенное исследование подтвердило эффективность методов на основе ключевых слов для решения этой задачи, достигнув точности классификации 96.3%.

Разработанные методы могут быть использованы как самостоятельные детекторы или как компоненты более сложных ансамблевых систем, обеспечивая высокую точность и надежность при проверке подлинности научных документов.

Спасибо за внимание! Готов ответить на ваши вопросы.

---

**Примечание для докладчика:**

- Время выступления: 5-7 минут
- Рекомендуется использовать презентацию с визуализацией результатов
- При упоминании конкретных цифр можно указывать на соответствующие слайды
- Важно поддерживать зрительный контакт с аудиторией
- В конце оставить время для вопросов

